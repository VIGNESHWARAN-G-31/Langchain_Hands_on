# ðŸ¦œðŸ”— LangChain Hands-on Repository

Welcome to the **LangChain Hands-on** repository!  
This is a **practical learning space** where we explore **LangChain**, a framework for building intelligent AI applications powered by Large Language Models (LLMs).  
It contains **step-by-step experiments**, **code examples**, and **mini-projects** designed to help beginners and enthusiasts understand how to create **AI agents, tools, and workflows**.

---

## ðŸ“Œ Why This Repo Exists

LLMs like  **Google Gemini** are powerful but often limited to answering single prompts.  
LangChain bridges this gap by enabling:
- Multi-step reasoning
- Tool integration (search, APIs, databases, etc.)
- Agents that decide *what to do next*
- Access to both structured and unstructured data

This repository is the result of **hands-on learning** â€” breaking down concepts and building small working projects to master LangChain.

---

## ðŸ“š What I Have Learnend :
- **LangChain Basics** â€“ Understanding core concepts: Tools, Agents, and Chains.
- **Tool Creation** â€“ How to connect your AI to external resources.
- **Agent Design** â€“ Making AI decide *which tool to use* and *when*.
- **AgentExecutor** â€“ Orchestrating multi-step AI workflows.
- **LLM Integration** â€“ Connecting with models like **Google Gemini**.
- **Mini Projects** â€“ Wikipedia search bot, custom retrievers, and more.
---

## ðŸ›  Libraries & Technologies Used

During this hands-on learning journey, we explored and implemented multiple tools, libraries, and technologies that power modern AI applications.

### ðŸ“¦ Python Libraries
- **LangChain** â€“ Core framework for building LLM-powered applications.
- **langchain-community** â€“ Community-maintained integrations.
- **langchain-google-genai** â€“ Integration with Google Gemini models.
- **langchain-openai** â€“ Integration with OpenAI GPT models.
- **langchainhub** â€“ Accessing shared prompts and workflows from LangChain Hub.
- **wikipedia** â€“ API wrapper for Wikipedia search.
- **chromadb** â€“ Local vector database for storing and retrieving embeddings.
- **faiss-cpu** â€“ High-performance similarity search library.
- **nomic-embed-text** â€“ Embedding model for converting text into vector form.
- **google-generativeai** â€“ Direct Gemini API client.
- **pandas** â€“ Data handling and manipulation.
- **python-dotenv** â€“ Environment variable management.

---

### ðŸ—„ Databases & Vector Stores
- **Chroma** â€“ Local vector store for embeddings.
- **FAISS** â€“ Facebook AI Similarity Search for large-scale vector retrieval.
- **Both Local & API-based Embeddings** â€“ Running embeddings locally (e.g., `nomic-embed-text`) and via APIs (e.g.Gemini).
---

### ðŸ¤– LLM Models Used
- **Google Gemini** (API-based) â€“ For reasoning, search, and agent execution.
- **Gemma 3** (Local) â€“ Low-level LLM running on system hardware.
- **Nomic Embeddings** â€“ Local embedding generation without internet.


---

